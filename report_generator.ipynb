{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "gemini = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0,\n",
    "    api_key=GEMINI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llama_32 = ChatGroq(\n",
    "    model=\"llama-3.1-70b-specdec\",\n",
    "    temperature=0,\n",
    "    api_key=GROQ_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llama = ChatGroq(\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    "    temperature=0,\n",
    "    api_key=GROQ_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('assets/module_2.txt', 'r') as file:\n",
    "    module_2_content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f'''\n",
    "    You are an expert in report generation. You are provided with summary of course videos of a module from the course\n",
    "    DevOps, DataOps and MLOps on Coursera. Your job is to provide a detailed academic report of this module. Provide the\n",
    "    report with minimum plagiarism possible. Write the report in an amateur manner as if you are a college student.\n",
    "    Do not output anything else other than the report. Provide the report in markdown format. Do not provide feedback.\n",
    "\n",
    "    Summary of Module: {module_2_content}\n",
    "    Report:\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**Module Report: DevOps, DataOps, and MLOps**\\n=============================================\\n\\n**Introduction**\\n---------------\\n\\nThis report provides an overview of the key concepts and techniques covered in the module on DevOps, DataOps, and MLOps. The module focuses on the essential steps and structure for a data scientist's first day at work, emphasizing the importance of organization and reproducibility in data science projects.\\n\\n**Setting Up Your Notebook**\\n-----------------------------\\n\\nThe module begins by creating a notebook in Colab and establishing a clear structure that includes sections for ingestion, exploratory data analysis (EDA), modeling, and conclusions. This structure is crucial for maintaining organization and reproducibility in data science projects. Additionally, the module highlights the importance of using GitHub to check in work and utilizing GitHub Codespaces for collaboration and version control.\\n\\n**The Four Key Steps in Data Science**\\n--------------------------------------\\n\\nThe module outlines the four key steps in data science:\\n\\n1. **Ingest**: Gather and import data, ensuring that everything needed for analysis is available.\\n2. **EDA**: Analyze the data to understand its characteristics, identify patterns, and determine if further data collection is necessary.\\n3. **Modeling**: Build predictive models based on the data, focusing on learning from the data to make predictions.\\n4. **Conclusions**: Formulate strong recommendations backed by data, ensuring that conclusions are well-supported and credible.\\n\\n**Simulations and MLOps Experiment Tracking**\\n------------------------------------------\\n\\nThe module explores the similarities between simulations and MLOps experiment tracking. Both processes aim to optimize outcomes through systematic experimentation. Simulations involve running multiple iterations of algorithms to find optimal solutions, such as minimizing travel distance. MLOps experiment tracking mirrors simulations by focusing on minimizing errors and optimizing metrics across various experiments.\\n\\n**Practical Applications**\\n---------------------------\\n\\nThe module highlights the practical applications of simulations and MLOps experiment tracking. Simulations can be used to visualize outcomes, such as the law of large numbers in gambling scenarios, demonstrating the likelihood of losing money over time. Experiment tracking in MLOps allows for detailed analysis of different runs, helping to refine models and improve performance.\\n\\n**K-means Clustering**\\n----------------------\\n\\nThe module focuses on K-means clustering, a popular unsupervised machine learning technique used to discover natural groupings in data. K-means clustering is an unsupervised machine learning method that identifies clusters in data without prior knowledge of labels. The goal is to find groups where samples within a group are more similar to each other than to those in different groups.\\n\\n**Key Techniques and Tools**\\n---------------------------\\n\\nThe module highlights the key techniques and tools used in K-means clustering, including:\\n\\n* Distance metrics, such as Euclidean distance, to measure similarity between data points in a multi-dimensional space.\\n* Standardization of data to ensure that all features contribute equally to the clustering process.\\n\\n**Diagnostic Tools for Clustering**\\n----------------------------------\\n\\nThe module introduces diagnostic tools for clustering, including:\\n\\n* Elbow Plot and Silhouette Analysis to determine the optimal number of clusters by visualizing the clustering performance.\\n* Intercluster distance maps to visualize the relationships between cluster centers, aiding in understanding the clustering structure.\\n\\n**Conclusion**\\n----------\\n\\nIn conclusion, this module provides a comprehensive overview of the essential steps and techniques in data science, including setting up a notebook, the four key steps in data science, simulations and MLOps experiment tracking, and K-means clustering. The module highlights the importance of organization, reproducibility, and collaboration in data science projects.\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_result = llama.invoke(prompt)\n",
    "llama_result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Module Report: DevOps, DataOps, and MLOps**\n",
       "=============================================\n",
       "\n",
       "**Introduction**\n",
       "---------------\n",
       "\n",
       "This report provides an overview of the key concepts and techniques covered in the module on DevOps, DataOps, and MLOps. The module focuses on the essential steps and structure for a data scientist's first day at work, emphasizing the importance of organization and reproducibility in data science projects.\n",
       "\n",
       "**Setting Up Your Notebook**\n",
       "-----------------------------\n",
       "\n",
       "The module begins by creating a notebook in Colab and establishing a clear structure that includes sections for ingestion, exploratory data analysis (EDA), modeling, and conclusions. This structure is crucial for maintaining organization and reproducibility in data science projects. Additionally, the module highlights the importance of using GitHub to check in work and utilizing GitHub Codespaces for collaboration and version control.\n",
       "\n",
       "**The Four Key Steps in Data Science**\n",
       "--------------------------------------\n",
       "\n",
       "The module outlines the four key steps in data science:\n",
       "\n",
       "1. **Ingest**: Gather and import data, ensuring that everything needed for analysis is available.\n",
       "2. **EDA**: Analyze the data to understand its characteristics, identify patterns, and determine if further data collection is necessary.\n",
       "3. **Modeling**: Build predictive models based on the data, focusing on learning from the data to make predictions.\n",
       "4. **Conclusions**: Formulate strong recommendations backed by data, ensuring that conclusions are well-supported and credible.\n",
       "\n",
       "**Simulations and MLOps Experiment Tracking**\n",
       "------------------------------------------\n",
       "\n",
       "The module explores the similarities between simulations and MLOps experiment tracking. Both processes aim to optimize outcomes through systematic experimentation. Simulations involve running multiple iterations of algorithms to find optimal solutions, such as minimizing travel distance. MLOps experiment tracking mirrors simulations by focusing on minimizing errors and optimizing metrics across various experiments.\n",
       "\n",
       "**Practical Applications**\n",
       "---------------------------\n",
       "\n",
       "The module highlights the practical applications of simulations and MLOps experiment tracking. Simulations can be used to visualize outcomes, such as the law of large numbers in gambling scenarios, demonstrating the likelihood of losing money over time. Experiment tracking in MLOps allows for detailed analysis of different runs, helping to refine models and improve performance.\n",
       "\n",
       "**K-means Clustering**\n",
       "----------------------\n",
       "\n",
       "The module focuses on K-means clustering, a popular unsupervised machine learning technique used to discover natural groupings in data. K-means clustering is an unsupervised machine learning method that identifies clusters in data without prior knowledge of labels. The goal is to find groups where samples within a group are more similar to each other than to those in different groups.\n",
       "\n",
       "**Key Techniques and Tools**\n",
       "---------------------------\n",
       "\n",
       "The module highlights the key techniques and tools used in K-means clustering, including:\n",
       "\n",
       "* Distance metrics, such as Euclidean distance, to measure similarity between data points in a multi-dimensional space.\n",
       "* Standardization of data to ensure that all features contribute equally to the clustering process.\n",
       "\n",
       "**Diagnostic Tools for Clustering**\n",
       "----------------------------------\n",
       "\n",
       "The module introduces diagnostic tools for clustering, including:\n",
       "\n",
       "* Elbow Plot and Silhouette Analysis to determine the optimal number of clusters by visualizing the clustering performance.\n",
       "* Intercluster distance maps to visualize the relationships between cluster centers, aiding in understanding the clustering structure.\n",
       "\n",
       "**Conclusion**\n",
       "----------\n",
       "\n",
       "In conclusion, this module provides a comprehensive overview of the essential steps and techniques in data science, including setting up a notebook, the four key steps in data science, simulations and MLOps experiment tracking, and K-means clustering. The module highlights the importance of organization, reproducibility, and collaboration in data science projects."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(llama_result.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_result = '''# Course Module Report: MLOps, DevOps, and DataOps\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The contemporary technological landscape demands sophisticated approaches to software development and machine learning operations. This module comprehensively explored the intricate domains of MLOps, DevOps, and DataOps, providing profound insights into modern operational methodologies that bridge theoretical knowledge with practical implementation.\n",
    "\n",
    "## Core Conceptual Framework\n",
    "\n",
    "### MLOps Fundamentals\n",
    "The module illuminated MLOps as a multidimensional discipline, consisting of four equally critical components:\n",
    "- DevOps integration\n",
    "- Data operations\n",
    "- Model improvement strategies\n",
    "- Business requirement framing\n",
    "\n",
    "By emphasizing this holistic approach, the course highlighted the complexity of effectively operationalizing machine learning models in contemporary technological ecosystems.\n",
    "\n",
    "### Philosophical Underpinnings\n",
    "Drawing inspiration from the Japanese Kaizen philosophy, the module explored continuous improvement as a fundamental operational principle. This concept, originally derived from automobile manufacturing, has been elegantly translated into software and machine learning contexts, promoting incremental enhancement and systematic quality control.\n",
    "\n",
    "## Operational Methodologies\n",
    "\n",
    "### DevOps Principles\n",
    "Key DevOps strategies included:\n",
    "- Infrastructure as code\n",
    "- Continuous integration and deployment\n",
    "- Automated testing mechanisms\n",
    "- Creating robust feedback loops\n",
    "\n",
    "These principles aim to streamline development processes, reduce operational friction, and enhance overall system reliability.\n",
    "\n",
    "### DataOps Approach\n",
    "The DataOps methodology focuses on:\n",
    "- Automating data system lifecycles\n",
    "- Encouraging interdepartmental collaboration\n",
    "- Breaking down organizational silos\n",
    "- Implementing consistent data product improvements\n",
    "\n",
    "## Technological Infrastructure\n",
    "\n",
    "### Cloud Computing Landscape\n",
    "The module extensively explored cloud infrastructure, highlighting:\n",
    "- Elastic storage systems\n",
    "- Serverless and containerized services\n",
    "- Integrated development environments\n",
    "- Specialized MLOps platforms\n",
    "\n",
    "### Maturity Models\n",
    "Different vendor approaches were analyzed, including:\n",
    "1. AWS MLOps Maturity Model: Emphasizing experimental to repeatable deployments\n",
    "2. Microsoft MLOps Model: Progressing from manual to automated systems\n",
    "3. Google MLOps Model: Transitioning from manual processes to comprehensive CI/CD automation\n",
    "\n",
    "## Development Practices\n",
    "\n",
    "### Environment Configuration\n",
    "Critical development practices discussed:\n",
    "- Cloud-based development platforms\n",
    "- Python virtual environment management\n",
    "- Project scaffolding techniques\n",
    "- Continuous testing methodologies\n",
    "\n",
    "### Automation Tools\n",
    "Key tools explored:\n",
    "- Makefiles for build process optimization\n",
    "- Dockerfiles for consistent runtime environments\n",
    "- Requirements.txt for dependency management\n",
    "- Testing frameworks like pytest and pylint\n",
    "\n",
    "## Emerging Trends\n",
    "\n",
    "The module identified several forward-looking trends:\n",
    "- Edge-based machine learning\n",
    "- Enhanced sustainability considerations\n",
    "- Advanced model governance\n",
    "- AutoML and model portability developments\n",
    "- Growing demand for specialized cloud computing professionals\n",
    "\n",
    "## Practical Application\n",
    "\n",
    "A practical text summarization application demonstration illustrated real-world MLOps implementation, showcasing:\n",
    "- Transformer model integration\n",
    "- Gradio interface development\n",
    "- GitHub Actions deployment\n",
    "- Access token management\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This module provided a comprehensive exploration of MLOps, DevOps, and DataOps, emphasizing the critical need for integrated, automated, and continuously improving technological ecosystems. By bridging theoretical knowledge with practical implementation strategies, the course equipped learners with essential skills for modern software and machine learning operations.\n",
    "\n",
    "## Key Takeaways\n",
    "- Embrace continuous improvement methodologies\n",
    "- Invest in cross-disciplinary skill development\n",
    "- Understand the interconnected nature of modern operational technologies\n",
    "- Prioritize automation and systematic enhancement strategies'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Course Module Report: MLOps, DevOps, and DataOps\n",
       "\n",
       "## Introduction\n",
       "\n",
       "The contemporary technological landscape demands sophisticated approaches to software development and machine learning operations. This module comprehensively explored the intricate domains of MLOps, DevOps, and DataOps, providing profound insights into modern operational methodologies that bridge theoretical knowledge with practical implementation.\n",
       "\n",
       "## Core Conceptual Framework\n",
       "\n",
       "### MLOps Fundamentals\n",
       "The module illuminated MLOps as a multidimensional discipline, consisting of four equally critical components:\n",
       "- DevOps integration\n",
       "- Data operations\n",
       "- Model improvement strategies\n",
       "- Business requirement framing\n",
       "\n",
       "By emphasizing this holistic approach, the course highlighted the complexity of effectively operationalizing machine learning models in contemporary technological ecosystems.\n",
       "\n",
       "### Philosophical Underpinnings\n",
       "Drawing inspiration from the Japanese Kaizen philosophy, the module explored continuous improvement as a fundamental operational principle. This concept, originally derived from automobile manufacturing, has been elegantly translated into software and machine learning contexts, promoting incremental enhancement and systematic quality control.\n",
       "\n",
       "## Operational Methodologies\n",
       "\n",
       "### DevOps Principles\n",
       "Key DevOps strategies included:\n",
       "- Infrastructure as code\n",
       "- Continuous integration and deployment\n",
       "- Automated testing mechanisms\n",
       "- Creating robust feedback loops\n",
       "\n",
       "These principles aim to streamline development processes, reduce operational friction, and enhance overall system reliability.\n",
       "\n",
       "### DataOps Approach\n",
       "The DataOps methodology focuses on:\n",
       "- Automating data system lifecycles\n",
       "- Encouraging interdepartmental collaboration\n",
       "- Breaking down organizational silos\n",
       "- Implementing consistent data product improvements\n",
       "\n",
       "## Technological Infrastructure\n",
       "\n",
       "### Cloud Computing Landscape\n",
       "The module extensively explored cloud infrastructure, highlighting:\n",
       "- Elastic storage systems\n",
       "- Serverless and containerized services\n",
       "- Integrated development environments\n",
       "- Specialized MLOps platforms\n",
       "\n",
       "### Maturity Models\n",
       "Different vendor approaches were analyzed, including:\n",
       "1. AWS MLOps Maturity Model: Emphasizing experimental to repeatable deployments\n",
       "2. Microsoft MLOps Model: Progressing from manual to automated systems\n",
       "3. Google MLOps Model: Transitioning from manual processes to comprehensive CI/CD automation\n",
       "\n",
       "## Development Practices\n",
       "\n",
       "### Environment Configuration\n",
       "Critical development practices discussed:\n",
       "- Cloud-based development platforms\n",
       "- Python virtual environment management\n",
       "- Project scaffolding techniques\n",
       "- Continuous testing methodologies\n",
       "\n",
       "### Automation Tools\n",
       "Key tools explored:\n",
       "- Makefiles for build process optimization\n",
       "- Dockerfiles for consistent runtime environments\n",
       "- Requirements.txt for dependency management\n",
       "- Testing frameworks like pytest and pylint\n",
       "\n",
       "## Emerging Trends\n",
       "\n",
       "The module identified several forward-looking trends:\n",
       "- Edge-based machine learning\n",
       "- Enhanced sustainability considerations\n",
       "- Advanced model governance\n",
       "- AutoML and model portability developments\n",
       "- Growing demand for specialized cloud computing professionals\n",
       "\n",
       "## Practical Application\n",
       "\n",
       "A practical text summarization application demonstration illustrated real-world MLOps implementation, showcasing:\n",
       "- Transformer model integration\n",
       "- Gradio interface development\n",
       "- GitHub Actions deployment\n",
       "- Access token management\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "This module provided a comprehensive exploration of MLOps, DevOps, and DataOps, emphasizing the critical need for integrated, automated, and continuously improving technological ecosystems. By bridging theoretical knowledge with practical implementation strategies, the course equipped learners with essential skills for modern software and machine learning operations.\n",
       "\n",
       "## Key Takeaways\n",
       "- Embrace continuous improvement methodologies\n",
       "- Invest in cross-disciplinary skill development\n",
       "- Understand the interconnected nature of modern operational technologies\n",
       "- Prioritize automation and systematic enhancement strategies"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(claude_result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
